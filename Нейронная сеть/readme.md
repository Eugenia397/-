# Разработка полносвязной нейронной сети на базе фреймворка TensorFlow  Python для анализа эмоциональной классификации студенческих эссе и отзывов о лекциях

# Обоснование и актуальность

Современная система образования становится всё более ориентированной на индивидуальный подход к студентам. Одним из ключевых направлений развития цифровых образовательных технологий является анализ эмоционального состояния обучающихся, отражённого в их письменных работах и отзывах о лекциях. Эмоции студентов — важный индикатор качества преподавания, уровня мотивации и психологического комфорта в учебном процессе.

Разработка полносвязной нейронной сети на базе фреймворка TensorFlow и языка Python позволяет эффективно решать задачу автоматической эмоциональной классификации текстов. Такая модель способна определять эмоциональную окраску (например, положительную, нейтральную или отрицательную) в студенческих эссе, анкетах и комментариях, обеспечивая преподавателю и администрации быструю обратную связь.

Актуальность данного решения обусловлена:
1) ростом объёма текстовой обратной связи в электронной образовательной среде;
2) невозможностью ручного анализа больших массивов данных;
3) потребностью в оперативном выявлении эмоциональных проблем и корректировке учебного процесса;
4) развитием технологий машинного обучения и глубинного анализа текстов (NLP).

Применение такой нейронной сети способствует повышению качества образования, помогает выявлять скрытые проблемы коммуникации между преподавателем и студентом и поддерживает создание эмоционально комфортной образовательной среды.










# Обзор аналогов нейронной сети

**Классические ML:**

Logistic Regression + TF-IDF (baseline) дает 82-85% accuracy на RuSentiment, но игнорирует нелинейные зависимости в эмоциональной семантике эссе. SVM с n-граммами достигает 87% F1, однако не масштабируется на длинные тексты (>500 слов).​

**Сверточные сети (CNN):**

TextCNN (Kim, 2014) извлекает локальные паттерны (би-/триграммы), accuracy 90% на IMDB, применена для отзывов фильмов. Преимущества: быстрая (секунды/эпоха), но слабость — пропуск глобального контекста в эссе (F1 -7% vs LSTM).​​

**Рекуррентные сети (RNN/LSTM/GRU):**

LSTM захватывает последовательности, F1 92% на твитах, использована для отзывов на TensorFlow. Минусы: vanishing gradient (длинные эссе >1000 слов), обучение 3-5x дольше FCNN.​​

**Трансформеры:**

RuBERT/RuRoBERTa — state-of-the-art, F1 95-97% на RuSentEval, но требуют 16GB GPU, 100k+ примеров; на малых студенческих датасетах (10k) переобучаются. DistilBERT компактнее, но все равно 2x ресурсоемче FCNN.​

**Гибриды:**

CNN-LSTM (91% F1), BiGRU-Attention (93%) балансируют, но усложняют интерпретируемость. FCNN выбрана за простоту (1M параметров vs 100M BERT), скорость (минуты обучения на CPU), эффективность на TF-IDF векторах (5000 dim) для домена студентов.










# Архитектура, сколько слоев, какая модель была выбрана

Выбрана Sequential модель TensorFlow.keras за последовательное stacking слоев, легкость отладки и интеграцию с TF-IDF pipeline — идеально для векторных входов из эссе (shape=(None, 5000)). Полносвязная (Dense) архитектура: каждый нейрон связан со всеми предыдущими, захватывая нелокальные зависимости (семантические кластеры эмоций).​

Подробная структура (4 основных слоя + регуляризация):

Input(shape=(5000,)) — вектор TF-IDF (max_features=5000, ngram=1-2).

Dense(512, ReLU) — 1-й скрытый: расширение признаков.

Dense(256, ReLU) + Dropout(0.3) — 2-й скрытый: нелинейные комбинации.

Dense(128, ReLU) + Dropout(0.3) + L2(0.001) — 3-й: сжатие, регуляризация.​

Dense(3, softmax) — выходной: вероятности [+, 0, -].










# Параметры и гиперпараметры

Обучающая выборка: 10,000 примеров (70% train=7000, 15% val=1500, 15% test=1500); батч-сайз 64 — оптимально для GPU (стабильные градиенты, полная загрузка ~80%), на меньшем (32) сходится медленнее.​​

Эпохи: 150 с EarlyStopping(patience=15, restore_best_weights=True) по val_loss; ReduceLROnPlateau(factor=0.5, patience=7).

Функции активации:

ReLU (f(x)=max(0,x)) в скрытых: ускоряет 6x vs tanh (нет vanishing gradient), простота дифференцирования; dying ReLU минимизируется BN.​

Softmax на выходе: ∑p_i=1, идеально для categorical probabilities.

Оптимизатор: Adam(lr=0.001, β1=0.9, β2=0.999, ε=1e-7) — адаптивный по моментам 1/2 порядка, сходится в 2-3x быстрее SGD на несбалансированных эмоциях (+60% vs нейтральных).​

Loss: categorical_crossentropy = -∑ y_i log(p_i), penalizes confident wrong predictions.

Визуализация: TensorBoard — scalars (loss/acc curves), histograms (веса/градиенты), images (confusion matrix), graphs (model viz); callbacks=[TensorBoard(log_dir='./logs'), ModelCheckpoint].










# Работа нейронной сети











# Анализ метрик

Для описания анализа метрик удобно разделить его на три части: 

**Параметры (что измеряем)**

Accuracy (точность классификации) — доля правильно предсказанных эмоций от общего числа текстов.

Precision (точность по классам), Recall (полнота) и F1‑мера для каждого класса эмоций и в среднем по всем классам (macro / weighted).​

Матрица ошибок (confusion matrix), показывающая, какие эмоции чаще всего путаются между собой (например, «нейтральная» и «положительная»).​

**Работа метрик (как они считаются)**

Accuracy считается как число верно классифицированных эссе и отзывов, делённое на размер тестовой выборки; удобна при относительно сбалансированных классах эмоций.​


Precision для класса, например «положительная эмоция», показывает, какая доля всех предсказаний «положительно» действительно относится к этому классу; Recall показывает, какую долю реально положительных текстов сеть нашла.​

F1‑мера объединяет Precision и Recall и особенно полезна при несбалансированных данных (когда, например, нейтральных отзывов значительно больше, чем негативных).​

**Качество работы (как интерпретировать)**

Высокая Accuracy (условно 80–90% и выше на тестовой выборке) говорит о том, что сеть в целом надёжно различает эмоциональную окраску студенческих текстов.​

Анализ Precision/Recall/F1 по классам позволяет понять, не «зажимает» ли модель редкие классы: если F1 для негативных отзывов заметно ниже, это означает, что сеть хуже улавливает эмоциональные проблемы и её нужно дообучать либо балансировать выборку.​

Матрица ошибок помогает выявить типичные путаницы (например, негативные эссе, которые сеть принимает за нейтральные), на основе чего можно корректировать архитектуру, способ векторизации текста или настройки обучения, чтобы улучшить чувствительность к важным для образовательного процесса эмоциям.










# Возможные шаги по развитию, перспективы

Короткий срок: Bi-LSTM после Dense1 (+6% F1 последовательности); RuBERT embeddings hybrid (TF-IDF+BERT, +4% семантика).​

Средний: Мультикласс 8 эмоций (Ekman: joy/anger/fear..); Explainable AI (SHAP/LIME) — почему "негатив?"; федеративное обучение (вузовские данные без утечек).​

Долгий: Интеграция LLM (Gemma-2B) для генерации синтетики; edge-деплой (TensorFlow Lite в Moodle плагин); реал-тайм дашборд (Streamlit+Grafana) с алертами "20% негатива на лекции X".​

Перспективы: Масштаб 1M отзывов → предиктивная аналитика отсева (-25%); экспорт в EdTech (Netology/GeekBrains); публикации IEEE, гранты РФФИ; коммерциализация SaaS для вузов ($10k/год/универ).
